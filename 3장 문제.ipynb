{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617c723c",
   "metadata": {},
   "source": [
    "# 3-1 머신 러닝 (Machine Learning)\n",
    "\n",
    "## Q1 \n",
    "\n",
    "다음 중 비지도 학습의 적용 사례에 해당하지 않는 것은 무엇인가요?\n",
    "\n",
    "1) 사용자의 상품 구매이력을 바탕으로 사용자가 지닌 잠재적 특징을 추출합니다.\n",
    "\n",
    "2) 음성 주파수 정보에서 발음 정보를 나타내는 주파수를 뽑아 냅니다.\n",
    "\n",
    "3) 사용자들의 구매 이력을 바탕으로 상품들의 재구매 여부를 예측합니다.\n",
    "\n",
    "4) 네비게이션 사용자의 이동 동선을 파악하여 비슷한 생활 유형로 그룹화합니다.\n",
    "\n",
    "\n",
    "<font color='red'> 정답 3 번: 재구매 여부를 맞추는 것은 지도 학습의 분류(Classification)입니다.</font>\n",
    "\n",
    "## Q2\n",
    "\n",
    "데이터사이언티스트 지희는 초콜렛 원료인 카카오 선물에 투자를 담당하는 펀드 매니저로부터 \n",
    "\n",
    "카카오 가격에 영향을 미치는 요인을 조사해서 앞으로의 카카오 가격을 예측하는 머신러닝 모델 개발 요청을 받았습니다.\n",
    "\n",
    "펀드 매니저는 평가는 최근 한 달의 카카오 가격을 예측 가격와 실제 가격과의 평균제곱오차로 하겠다고 합니다.\n",
    "\n",
    "이 프로젝트에서 가장 적합한 검증데이터 선택 방법은 무엇입니까?\n",
    "\n",
    "1) 계층적 선택법\n",
    "\n",
    "2) 그룹화 선택법\n",
    "\n",
    "3) 임의 선택법\n",
    "\n",
    "4) 시계열 선택법\n",
    "\n",
    "<font color='red'> 정답 4 번: 평가를 시점 기준으로 이전과 이후로 나누고 있으므로 시점 기준으로 이전과 이후를 검증 학습데이터와 검증 평가데이터로 나누는 시계열 선택법이 적합합니다.</font>\n",
    "\n",
    "## Q3\n",
    "\n",
    "교차검증에 대한 설명으로 가장 적합하지 않은 것은 무엇인가요?\n",
    "\n",
    "1) K-폴드 교차 검증은 데이터를 K개의 부분 집합으로 나누고, 각각의 부분 집합을 한 번씩 검증 세트로 사용하여 모델을 평가합니다.\n",
    "\n",
    "2) 교차 검증은 큰 규모의 데이터셋을 검증하는 데 연산 자원에 대한 부담을 줄여 줍니다.\n",
    "\n",
    "3) 변인이 많아 정교한 검증이 요구가 될 경우 채택을 합니다\n",
    "\n",
    "4) 검증 결과의 신뢰도를 높히기 위해 여러 번 반복할 수 있습니다.\n",
    "\n",
    "<font color='red'> 정답 2 번: 기본적으로 폴드수 만큼의 학습가 검증을 반복하므로 연산 자원이 폴드수에 비례하여 소요됩니다.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e390704a",
   "metadata": {},
   "source": [
    "# 3-2 일반화\n",
    "\n",
    "\n",
    "## Q1\n",
    "\n",
    "과적합이 발생할 경우에 나타나는 상황과 거리가 먼 것은 무엇인가요?\n",
    "\n",
    "1) 학습 데이터의 성능을 높일 수록, 평가 데이터의 성능은 낮아 집니다.\n",
    "\n",
    "2) 학습 데이터의 패턴을 지나치게 에측에 반영하여 모델의 편향이 낮아진 상태입니다.\n",
    "\n",
    "3) 입력 변수의 선별을 수행했다면, 수행 과정에서 지나치게 데이터 손실이 발생한 상태입니다.\n",
    "\n",
    "4) 데이터의 작은 변화에도 민감하게 반응하여 모델의 분산이 높아진 상태입니다.\n",
    "\n",
    "<font color='red'>정답 3 번: 선별 과정에서 지나치게 데이터 손실이 발생했다면 과소 적합이 발생합니다.</font>\n",
    "\n",
    "## Q2\n",
    "\n",
    "머신러닝 모델의 일반화 성능을 높이기 위한 방안으로 가장 거리가 먼 것을 무엇인가요?\n",
    "\n",
    "1) 머신 러닝 모델의 최적의 하이퍼 파라메터를 탐색을 수행합니다.\n",
    "\n",
    "2) 모델 검증시 좋은 성능을 얻기 위해 검증 방법을 바꿉니다.\n",
    "\n",
    "3) 최적의 성능을 보이는 속성(입력 변수)을 선별합니다.\n",
    "\n",
    "4) 대상 변수와 관련 된 현상을 보다 잘 반영하는 파생 변수를 만들어 봅니다.\n",
    "\n",
    "<font color='red'>정답 2 번: 평가 상황을 잘 반영하여 모델의 일반화 성능을 제대로 측정할 수 있는 검증 방법을 택해야합니다.</font>\n",
    "\n",
    "## Q3 \n",
    "\n",
    "속성 선택법에 대한 설멸으로 잘못된 것은 무엇인가요?\n",
    "\n",
    "1) 일반적으로 필터(Filter) 기반 방법은 대상 변수와 입력 변수(속성)간의 연관성을 계산해야하기 때문에 웨퍼(Wrapper)에 비해 연산 자원이 많이 필요합니다.\n",
    "\n",
    "2) 웨퍼(Wrapper) 기반 방법은 입력 변수 간의 상호작용을 고려할 수 있지만, 필터(Filter) 방법은 고려하기 어렵습니다.\n",
    "\n",
    "3) 웨퍼(Wrapper) 기반 방법 중 All Subset 방법은 최적의 입력 변수를 도출할 수 있지만, 연산량이 커서 작은 규모의 데이터에만 적용이 가능합니다.\n",
    "\n",
    "4) 웨퍼(Wrapper) 기반 방법 중 단계적 전진선택법에서는 전진선택 후에 후진 제거시 성능에 개선이 있다면 선택되었던 변수가 제외되기도 합니다.\n",
    "\n",
    "<font color='red'>정답 1 번: 웨퍼(Wrapper) 방법은 머신 러닝 모델의 학습과 평가가 필요하므로 일반적으로 보다 많은 연산 자원이 필요합니다.</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5785cf85",
   "metadata": {},
   "source": [
    "# 3-3 학습 알고리즘\n",
    "\n",
    "\n",
    "## Q1\n",
    "\n",
    "다음 중 경사 하강법에 대한 설명 중 잘못된 것은 무엇인가요?\n",
    "\n",
    "1) 확률적 경사 하강법은 비슷한 성격의 데이터가 정렬되어 학습이 되면 보다 안정적으로 결과를 얻을 수 있습니다.\n",
    "\n",
    "2) 표준화, 정규화 같이 입력 변수들의 폭을 균일하게 해주는 처리 과정은 안정이고 효율적인 경사 하강법에 도움이 됩니다.\n",
    "\n",
    "3) 경사 하강법은 전역 최적점(Global Optimum) 보장하지는 않습니다.\n",
    "\n",
    "4) 확률적 경사 하강법은 전체 데이터셋을 메모리에 로드할 필요가 없어 대규모 데이터셋에서도 적용할 수 있습니다.\n",
    "\n",
    "<font color='red'> 정답 1 번: 확률적 경사 하강법은 각 배치(Batch)가 전체 데이터들을 잘 대표할수록 안정적인 성능을 보입니다. 정렬된 상태라면 정렬 기준에 편향성을 지니게 되어 전체 데이터들을 잘 대표하지 못할 가능성이 높습니다.</font>\n",
    "\n",
    "\n",
    "## Q2\n",
    "\n",
    "다음 중 최적화 알고리즘에 대한 설명으로 옳지 않은 것은 무엇인가요?\n",
    "\n",
    "1) EM(Expectation-Maximization) 알고리즘은 잠재 변수(Latent Variable)이 있는 확률 모델에서 최대우도추정(Maximum Likelihood Estimation)을 구하는 기법입니다.\n",
    "\n",
    "2) Metropolis-Hastings 알고리즘에서 제안된 상태의 수용확률을 계산하기 위해 현재까지 수용되었던 상태의 이동 평균을 사용합니다.\n",
    "\n",
    "3) EM(Expectation-Maximization) 알고리즘의 기대값(Expectation)에서는 현재 모수로 정의된 잠재 변수의 확률 분포에서 다음 단계 모수에 대한 로그 우도에 대한 기대값을 구합니다.\n",
    "\n",
    "4) 가우시안 혼합 모델의 잠재 변수(Latent Variable)에는 혼합 모델의 가우시안 분포들 중에서 각 관측값들이 어느 분포에서 생성된 것인지를 나타내는 변수가 있습니다.\n",
    "\n",
    "<font color='red'> 정답 2: 수용확률를 계산하기 위해 현재 상태만을 이용합니다.</font>\n",
    "\n",
    " \n",
    "## Q3\n",
    "\n",
    "경사 하강법으로 아래 함수의 최솟값인 x를 구하고자 합니다. 초기의 x값이 1이고 학습율은 0.5입니다. 1회 학습시 x의 값은 무엇인가요?\n",
    "\n",
    "$f(x) = x^2 - 4x + 1$ \n",
    "\n",
    "1) 0 \n",
    "\n",
    "2) 1\n",
    "\n",
    "3) 2\n",
    "\n",
    "4) 3\n",
    "\n",
    "\n",
    "<font color='red'> 정답 3 번:$f'(x) = 2x - 4, f'(1) = -2, x = 1 + 2 * 0.5 = 2$</font>\n",
    "\n",
    "\n",
    "# 3-4 \n",
    "\n",
    "## Q1 \n",
    "\n",
    "다음 중 클래스 불균형 문제의 해결을 통해 성능 향상을 기대해 볼만한 분류 지표로 묶은 것은 무엇인가요?\n",
    "\n",
    "\n",
    "(ㄱ) f1-점수(f1-score) (ㄴ) 정확도(Accuracy) (ㄷ) 매크로 재현율(Macro recall)  (ㄹ) 크로스 엔트로피\n",
    "\n",
    "\n",
    "1) (ㄱ), (ㄴ)\n",
    "\n",
    "2) (ㄱ), (ㄷ)\n",
    "\n",
    "3) (ㄴ), (ㄹ)\n",
    "\n",
    "4) (ㄷ), (ㄹ)\n",
    "\n",
    "<font color='red'> 정답 2 번: (ㄱ) 재현율과 정밀도의 조화평균인 f1-점수는 양성 클래스가 소수일 경우 재현율이 f1 score의 성능이 낮을 수 있습니다. 양성 클래스의 불균형을 완화 시켜 f1-score의 성능을 향상 시킬 수 있습니다. (ㄷ) Macro 재현율는 다중 분류시 클래스 별 평균을 사용하므로, 소수의 클래스의 오분류가 영향을 크게 미치므로, 소수의 클래스의 재현률을 높일 수록 성능을 향상시킬 수 있습니다.</font>\n",
    "\n",
    "## Q2\n",
    "\n",
    "\n",
    "보기 중에서 클래스 불균형을 해소하기 위한 샘플링 방법에 대한 설명 중 잘못된 것은 무엇인가요?\n",
    "\n",
    "1. 랜덤 오버 샘플링(Random Over Sampling): 소수 클래스의 데이터를 임의로 선택하고 이를 복제하여 다수의 클래스와 균형을 맞춥니다.\n",
    "\n",
    "\n",
    "2. 랜덤 언더 샘플링(Random Under Sampling): 다수 클래스의 데이터를 임의로 선택하여  제거하여 데이터셋을 균형있게 만듭니다.\n",
    "\n",
    "\n",
    "3. SMOTE (Synthetic Minority Over-sampling Technique): 소수 클래스의 데이터를 사용의 임의의 데이터를 선택하고 그 주변 이웃 K 개중 하나를 골라 둘을 잇는 선분 위에 점을 거리에 비례하여 샘플링하여 균형을 맞춥니다.\n",
    "\n",
    "\n",
    "4. Tomek Links: 각 데이터 포인트의 최근접 데이터 포인트가 서로 다른 클래스에 속할 경우, 이 때 다수의 클래스를 제거하여 균형을 맞춥니다.\n",
    "\n",
    "<font color='red'>  정답 3: ADASYN에 대한 설명입니다. </font>\n",
    "\n",
    "## Q3\n",
    "\n",
    "다음 중 클래스 불균형을 해소하기 위한 방법 중에서 성격이 다른 것은 무엇인가요?\n",
    "\n",
    "\n",
    "1) SMOTE(Synthetic Minority Over-sampling Technique) \n",
    "\n",
    "2) ADASYN(Adaptive Synthetic Sampling)\n",
    "\n",
    "3) 클래스 분류 임계점 조정\n",
    "\n",
    "4) 랜덤 오버 샘플링(Random Over Sampling)\n",
    "\n",
    "<font color='red'> 정답 3: 1, 2, 4 는 오버 샘플링을 통한 해소방법 입니다. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1cab7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
